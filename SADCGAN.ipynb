{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ed369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from utils import Generator, Discriminator, DatasetImages, init_weights_ ,Self_Attn\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "from DiffAugment_pytorch import DiffAugment\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pprint\n",
    "from torchvision.utils import make_grid\n",
    "import fid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c15cf869",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "policy = 'color,translation,cutout'\n",
    "# Utility functions\n",
    "def cuda(data):\n",
    "    if torch.cuda.is_available():\n",
    "        return data.cuda()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699f9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = pathlib.Path(\"outputs\") / \"out\"\n",
    "output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Prepare tensorboard writer\n",
    "writer = SummaryWriter(output_path)\n",
    "args_d = {}\n",
    "args_d[\"time\"] = datetime.now()\n",
    "# Log hyperparameters as text\n",
    "writer.add_text(\n",
    "        \"hyperparameter\",\n",
    "        pprint.pformat(args_d).replace(\n",
    "            \"\\n\", \"  \\n\"\n",
    "        ),  # markdown needs 2 spaces before newline\n",
    "        0,\n",
    "    )\n",
    "\n",
    "# Fix a random latent input for samples\n",
    "fixed_z = cuda(torch.randn(64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e92f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path(\"data\")\n",
    "tform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ]\n",
    "    )\n",
    "dataset = DatasetImages(\n",
    "        data_path,\n",
    "        transform=tform,\n",
    "    )\n",
    "dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e0f7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_kwargs = {\"nrow\": 8, \"normalize\": True}\n",
    "n_mosaic_cells = 64\n",
    "sample_showcase_ix = (\n",
    "        0  \n",
    "    )\n",
    "    \n",
    "    \n",
    "writer.add_image(\n",
    "        \"true_data\",\n",
    "        make_grid(\n",
    "            torch.stack([dataset[i] for i in range(n_mosaic_cells)]),\n",
    "            **mosaic_kwargs\n",
    "        ),\n",
    "        0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9445dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(steps, batch_size = 64, z_dim = 100, attn = True):\n",
    "    z = cuda(torch.randn(batch_size, z_dim))\n",
    "    # Initialize model\n",
    "    G = cuda(Generator(batch_size, attn))\n",
    "    D = cuda(Discriminator(batch_size, attn))\n",
    "    \n",
    "    # Make directory for samples and models\n",
    "    cwd = os.getcwd()\n",
    "    if not os.path.exists(cwd+'/dir'):\n",
    "        os.makedirs(cwd+'/dir')\n",
    "    #os.makedirs(cwd+ '/fid_temp_folder')\n",
    "\n",
    "    # Initialize optimizer with filter, lr and coefficients\n",
    "    g_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, G.parameters()), 0.0004, [0.5,0.99])\n",
    "    d_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, D.parameters()), 0.0001, [0.5,0.99])\n",
    "    G.apply(init_weights_)\n",
    "    D.apply(init_weights_)\n",
    "    # Load data\n",
    "    Iter = iter(dataloader)\n",
    "    \n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # ================== Train D ================== #\n",
    "        D.train(); G.train()\n",
    "        try:\n",
    "            real_images = next(Iter)\n",
    "        except:\n",
    "            Iter = iter(dataloader)\n",
    "            real_images = next(Iter)\n",
    "        iter_length = len(list(real_images))\n",
    "        # Compute loss with real images\n",
    "        d_out_real = D((DiffAugment(cuda(real_images), policy=policy)))\n",
    "        #no diffaugm\n",
    "        #d_out_real = D(cuda(real_images))\n",
    "        d_loss_real = torch.nn.ReLU()(1.0 - d_out_real).mean()\n",
    "        \n",
    "        # Compute loss with fake images\n",
    "        z = cuda(torch.randn(batch_size, z_dim))\n",
    "        fake_images = G(z)\n",
    "        d_out_fake = D(DiffAugment(fake_images, policy=policy))\n",
    "        #no diffaug\n",
    "        #d_out_fake = D(fake_images)\n",
    "        d_loss_fake = torch.nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "        \n",
    "        # Backward + Optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad(); g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ================== Train G ================== #\n",
    "        # Create random noise\n",
    "        z = cuda(torch.randn(batch_size, z_dim))\n",
    "        fake_images = G(z)\n",
    "        g_out_fake = D((DiffAugment(fake_images, policy=policy)))\n",
    "        #noo diffaug\n",
    "        #g_out_fake = D(fake_images)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "        d_optimizer.zero_grad(); g_optimizer.zero_grad()\n",
    "        g_loss_fake.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Print out log info\n",
    "        if (step + 1) % 20 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            expect = elapsed/(step + 1)*(steps-step-1)\n",
    "            elapsed = str(timedelta(seconds=elapsed))\n",
    "            expect = str(timedelta(seconds=expect))\n",
    "            clear_output(wait=True)\n",
    "            print(\"Elapsed [{}], Expect [{}], step [{}/{}], D_real_loss: {:.4f}, \"\n",
    "                  \" ave_generator_gamma: {:.4f}\".\n",
    "                  format(elapsed,expect,step + 1,steps,d_loss_real.item(),G.attn.gamma.mean().item()))\n",
    "            \n",
    "        if step % 50 == 0:\n",
    "                writer.add_scalar(\"d_real\", d_loss_real.mean().item(), step)\n",
    "                writer.add_scalar(\"d_fake\", d_loss_fake.mean().item(), step)\n",
    "                writer.add_scalar(\"gen\", g_loss_fake.mean().item(), step)\n",
    "                writer.add_scalar(\n",
    "                    \"D_loss\", (d_loss).item(), step\n",
    "                )\n",
    "                writer.add_scalar(\"G_loss\", g_loss_fake.item(), step)\n",
    "        #if step % 500 == 0:\n",
    "                # Save checkpoint (and potentially overwrite an existing one)\n",
    "                #torch.save(generator, output_path / \"model.pt\")\n",
    "        # Sample images\n",
    "        if (step +1) % (1000) == 0 :\n",
    "            #G.eval()\n",
    "            #D.eval() \n",
    "            fake_images= G(fixed_z)\n",
    "            save_image(denorm(fake_images), os.path.join('./dir', '{}_fake.jpg'.format(step + 1)))\n",
    "            # reshape the generated images\n",
    "            #images = images.transpose((0, 3, 1, 2))\n",
    "            #images /= 255\n",
    "            #fake_images= list(map(lambda x: (x.detach().permute(0, 2, 3, 1) / 2) + 0.5, fake_images))\n",
    "            c=0\n",
    "            for img in fake_images: \n",
    "                c +=1\n",
    "                save_image(denorm(img),os.path.join('./fid_temp_folder', '{}_fake.jpg'.format(c)))\n",
    "                    #generated_images += 1\n",
    "                # Generate fake images\n",
    "            gen_imgs_eval = G(fixed_z)\n",
    "            fid = fid_score.calculate_fid_given_paths(\n",
    "                        ('./data', './fid_temp_folder'),\n",
    "                        64, \n",
    "                        True,\n",
    "                        2048  # using he default value\n",
    "                    )\n",
    "\n",
    "                    # print the compute fid value:\n",
    "            print(\"FID at epoch %d: %.6f\" % (step, fid))\n",
    "\n",
    "                    # log the fid value in tensorboard:\n",
    "            writer.add_scalar(\"FID\", fid, step)\n",
    "                    # note that for fid value, the global step is the epoch number.\n",
    "                    # it is not the global step. This makes the fid graph more informative\n",
    "                # Generate nice mosaic\n",
    "            writer.add_image(\n",
    "                    \"fake\",\n",
    "                    make_grid(fake_images, **mosaic_kwargs),\n",
    "                    step,\n",
    "                )\n",
    "        # Save models\n",
    "        if (step+1) % (1000) == 0:\n",
    "            torch.save(G.state_dict(),os.path.join('./models', '{}_G.pth'.format(step + 1)))\n",
    "            torch.save(D.state_dict(),os.path.join('./models', '{}_D.pth'.format(step + 1)))\n",
    "        if(step == (59000)):\n",
    "            gen = G.to(\"cuda\")\n",
    "            #d = D.to(\"cuda\")\n",
    "            #A = Self_Attn(3).to(\"cuda\")\n",
    "            #x = real_images\n",
    "            writer.add_graph(gen, input_to_model=z)\n",
    "            #writer.add_graph(d, input_to_model=fake_images)\n",
    "            #writer.add_graph(A, input_to_model=fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34acdd8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [0:58:35.399427], Expect [0:00:00], step [60000/60000], D_real_loss: 0.0430,  ave_generator_gamma: 0.0000\n",
      "Warning: number of images is not a multiple of the batch size. Some samples are going to be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  5.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID at epoch 59999: 291.899042\n",
      "Done training part 1\n"
     ]
    }
   ],
   "source": [
    "train(steps = 60000,batch_size = 64,z_dim = 100, attn = False)\n",
    "print('Done training part 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16011747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python projector.py --label=0 --label-dim=10 --outdir=out --target=data/plane_10.jpg --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98776eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gif creation\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "font = ImageFont.truetype(\"./demo/arial.ttf\", 18)\n",
    "def create_image_with_text(img, wh, text):\n",
    "    width, height = wh\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((width, height), text, font = font, fill=\"white\")\n",
    "    return img\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(100, 20001, 100):\n",
    "    img = Image.open('samples_mnist/{}_fake.png'.format(str(i)))\n",
    "    #img1 = Image.open('samples_mnist_attn/{}_fake.png'.format(str(i)))\n",
    "    width, height = img.size\n",
    "    expand = Image.new(img.mode, (width*2 + 10, height + 40), \"black\")\n",
    "    expand.paste(img, (0, 0))\n",
    "    #expand.paste(img1, (width + 10, 0))\n",
    "    epoch = round(i*64/60000,2)\n",
    "    new_frame = create_image_with_text(expand,(10,258), \"After \"+str(epoch)+\" epoches\")\n",
    "    new_frame = create_image_with_text(new_frame,(10,238), \"Without Attention\")\n",
    "    #new_frame = create_image_with_text(new_frame,(width + 20,238), \"With Attention\")\n",
    "    frames.append(new_frame)\n",
    "    \n",
    "frames[0].save('./demo/comparison_mnist.gif', format='GIF',\n",
    "               append_images=frames[1:],\n",
    "               save_all=True,\n",
    "               duration=60, loop=0)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
